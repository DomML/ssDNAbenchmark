{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Objectifs\n",
    "\n",
    "+ Obtenir et distribuer des paires bound (protein + ssDNA) / unbound (proteine seules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "update_biounit = True\n",
    "clusterNumber = 100\n",
    "#clusterNumber = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from utils.utils_rcsb import *\n",
    "from utils.utils_bash import *\n",
    "from utils.utils_benchmark import *\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "\n",
    "from rcsbsearch import Attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from vmd import molecule, atomsel\n",
    "from pdbfixer import pdbfixer\n",
    "from simtk.openmm.app import PDBFile\n",
    "\n",
    "from glob import glob\n",
    "import subprocess\n",
    "from itertools import groupby, count, chain, combinations, permutations\n",
    "from collections.abc import Iterable\n",
    "import os, json, sys\n",
    "import requests, gzip\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from os.path import getmtime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from multiprocessing.pool import ThreadPool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Find DNA/protein and protein only chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Get PDBid of bound and unbound proteins"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Run python ./queryPDB.py from time to time (cron is the best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_q = open(\"./pdb_query/protein.txt\", \"r\").read().split(\"\\n\")\n",
    "dna_q = open(\"./pdb_query/dna.txt\", \"r\").read().split(\"\\n\")\n",
    "rna_q = open(\"./pdb_query/rna.txt\", \"r\").read().split(\"\\n\")\n",
    "hyb_q = open(\"./pdb_query/hybrid.txt\", \"r\").read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_with_dna = set(prot_q) & set(dna_q) - set(rna_q) - set(hyb_q)\n",
    "protein_without_dna = set(prot_q) - set(dna_q) - set(rna_q) - set(hyb_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3030, 121459)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(protein_with_dna), len(protein_without_dna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Download bound PDBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def download_file(url, target):\n",
    "    r = requests.get(url, stream=True)\n",
    "    if r.status_code == 404:\n",
    "        return False\n",
    "    # Total size in bytes.\n",
    "    total_size = int(r.headers.get('content-length', 0))\n",
    "    block_size = 1024 #1 Kibibyte\n",
    "    with open(target, 'wb') as f:\n",
    "        for data in r.iter_content(block_size):\n",
    "            f.write(data)\n",
    "    return True\n",
    "\n",
    "def download_file_stream(url, target, pb = tqdm):\n",
    "    # Streaming, so we can iterate over the response.\n",
    "    r = requests.get(url, stream=True)\n",
    "    # Total size in bytes.\n",
    "    total_size = int(r.headers.get('content-length', 0))\n",
    "    block_size = 1024 #1 Kibibyte\n",
    "    t=tqdm(total=total_size, unit='iB', unit_scale=True)\n",
    "    with open(target, 'wb') as f:\n",
    "        for data in r.iter_content(block_size):\n",
    "            t.update(len(data))\n",
    "            f.write(data)\n",
    "    t.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## bio assemblies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Only download them if they are older than 1 hour\n",
    "ct = time.time()\n",
    "url = 'http://files.rcsb.org/pub/pdb/data/biounit/coordinates/all'\n",
    "target = \"all.txt\"\n",
    "try:\n",
    "    ft = getmtime(target)\n",
    "    if ct-ft > 3600:\n",
    "        download_file_stream(url, target)\n",
    "except:\n",
    "    download_file_stream(url, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "all_biounit = open(\"all.txt\", \"r\").read()\n",
    "all_biounit_files = uniq(re.findall(\"(.{4}.pdb[0-9]+\\.gz)\", open(\"all.txt\", \"r\").read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47409899c064e2f851008a5fc41b161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258269 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "protein_with_dna = [i.lower() for i in protein_with_dna]\n",
    "biounit_files_withDNA = uniq([biounit_f for biounit_f in tqdm(all_biounit_files) if biounit_f[:4] in protein_with_dna])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "146ba9f2ae084258a1374c3c38ba4869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dl_bio_unit(f):\n",
    "    f = f.lower()\n",
    "    ####\n",
    "    if os.path.exists(f\"pdb_bio/{f}\"):\n",
    "        os.remove(f\"pdb_bio/{f}\")\n",
    "    if os.path.exists(f\"pdb_bio/{f[:-3]}\"):\n",
    "        return\n",
    "    ####\n",
    "    url = f\"https://files.rcsb.org/download/{f}\"\n",
    "    download_file(url, f\"pdb_bio/{f}\")\n",
    "    \n",
    "    try:\n",
    "        with gzip.open(f\"pdb_bio/{f}\", \"rb\") as my_f:\n",
    "            data = my_f.read()\n",
    "            open(f\"pdb_bio/{f[:-3]}\", \"wb\").write(data)\n",
    "\n",
    "        os.remove(f\"pdb_bio/{f}\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "# Run 50 multiple threads. Each call will take the next element in urls list\n",
    "results = ThreadPool(50).imap_unordered(dl_bio_unit, biounit_files_withDNA)\n",
    "for r in tqdm(results, total = len(biounit_files_withDNA)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed297e574aa475d8d57c2d719961c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download biounit if not existing\n",
    "for f in tqdm(biounit_files_withDNA, total = len(biounit_files_withDNA)):\n",
    "    f = f.lower()\n",
    "    ####\n",
    "    if os.path.exists(f\"pdb_bio/{f}\"):\n",
    "        os.remove(f\"pdb_bio/{f}\")\n",
    "    if os.path.exists(f\"pdb_bio/{f[:-3]}\"):\n",
    "        continue\n",
    "    ####\n",
    "    url = f\"https://files.rcsb.org/download/{f}\"\n",
    "    download_file(url, f\"pdb_bio/{f}\")\n",
    "    \n",
    "    with gzip.open(f\"pdb_bio/{f}\", \"rb\") as my_f:\n",
    "        data = my_f.read()\n",
    "        open(f\"pdb_bio/{f[:-3]}\", \"wb\").write(data)\n",
    "    \n",
    "    os.remove(f\"pdb_bio/{f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Main structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb396d1053c4330a865465f8582c27b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3030 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "failed_dl = []\n",
    "def dl_str(f):\n",
    "    f = f.lower()\n",
    "    ####\n",
    "    if os.path.exists(f\"pdb_str/{f}.pdb\"):\n",
    "        return\n",
    "    ####\n",
    "    url = f\"https://files.rcsb.org/download/{f}.pdb\"\n",
    "    success = download_file(url, f\"pdb_str/{f}.pdb\")\n",
    "    if success == False:\n",
    "#         print(f)\n",
    "        failed_dl.append(f)\n",
    "    \n",
    "# Run 5 multiple threads. Each call will take the next element in urls list\n",
    "results = ThreadPool(50).imap_unordered(dl_str, protein_with_dna)\n",
    "for r in tqdm(results, total = len(protein_with_dna)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6uua',\n",
       " '6vu3',\n",
       " '6vmi',\n",
       " '6uty',\n",
       " '6vlz',\n",
       " '6uub',\n",
       " '6vz3',\n",
       " '7ena',\n",
       " '7enc',\n",
       " '7egc',\n",
       " '6vz2',\n",
       " '7omz',\n",
       " '7on0',\n",
       " '7b23',\n",
       " '7cr8',\n",
       " '6vyq',\n",
       " '6utx',\n",
       " '6vyt',\n",
       " '6vyr',\n",
       " '6vyu',\n",
       " '7egb',\n",
       " '6vys',\n",
       " '7b24',\n",
       " '7b20',\n",
       " '6vz7',\n",
       " '7omy',\n",
       " '6vz5',\n",
       " '7b1y']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_bound' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-00a6e726b205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_bound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"6WE\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboundId\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboundId\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_bound' is not defined"
     ]
    }
   ],
   "source": [
    "for i,r in df_bound.iterrows():\n",
    "    if \"6WE\" in r.boundId:\n",
    "        print(i, r.boundId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Analyse for ssDNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The idea is to analyse the main structure (first frame) or the biological assemblies (all frames merged) to identify dsDNA, and therefor ssDNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def get_consecutive_elements(data):\n",
    "    c = count()\n",
    "    val = list(list(g) for _, g in groupby(data, lambda x: x-next(c)))\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## find_pair analysis (find dsDNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92edac71186248d5a66dbb52cef7ab76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def analyse_findPair(s):\n",
    "    try:\n",
    "        ### Analyse main structure\n",
    "        str_pdb = glob(f\"pdb_str/{s}.pdb\")[0]\n",
    "        fatcat_pdb = str_pdb.replace(\"pdb_str\", \"results_findPair\")\\\n",
    "                                .replace(\"pdb\", \"fp\")\n",
    "        if not os.path.exists(fatcat_pdb):\n",
    "            fp, fp_err = find_pair(str_pdb)\n",
    "            with open(fatcat_pdb, \"w\") as f:\n",
    "                f.write(fp.replace(\"\\\\n\", \"\\n\"))\n",
    "\n",
    "        ### Analyse biological assembly\n",
    "        str_bio = sorted(glob(f\"pdb_bio/{s}.pdb[0-9]\"))\n",
    "        for b in str_bio:\n",
    "            fatcat_b = b.replace(\"pdb_bio\", \"results_findPair\")\\\n",
    "                        .replace(\"pdb\", \"fp\")\n",
    "            if not os.path.exists(fatcat_b):\n",
    "                # Only keep ATOM records\n",
    "                nb = open(b, \"r\").read().split(\"\\n\")\n",
    "                nb = [line for line in nb if line.startswith(\"ATOM\")]\n",
    "                nb = \"\\n\".join(nb)\n",
    "                open(f\"tmp_findpair.{s}.pdb\", \"w\").write(nb)\n",
    "                # Find pair\n",
    "                fp, fp_err = find_pair(f\"tmp_findpair.{s}.pdb\")\n",
    "                with open(fatcat_b, \"w\") as f:\n",
    "                    f.write(fp.replace(\"\\\\n\", \"\\n\"))\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(s, e)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        os.remove(f\"tmp_findpair.{s}.pdb\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "do_fp = False\n",
    "try:\n",
    "    ct = time.time()\n",
    "    ft = getmtime(\"last_run.txt\")\n",
    "    if ct-ft > 3600*12:\n",
    "        do_fp = True\n",
    "except:\n",
    "    open(\"last_run.txt\", \"w\").write(\"\")\n",
    "    do_fp = True\n",
    "\n",
    "for f in tqdm(protein_with_dna):\n",
    "    analyse_findPair(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## List DNA close to protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f3410ef2aea4542a8edb3a9ab30ff9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "do_run = False\n",
    "\n",
    "ct = time.time()\n",
    "ft = getmtime(\"last_run.txt\")\n",
    "if ct-ft > 3600*12:\n",
    "    do_run = True\n",
    "####    ####    ####    ####\n",
    "\n",
    "for s in tqdm(protein_with_dna):\n",
    "    if not do_run:\n",
    "        break\n",
    "    try:\n",
    "        ### Analyse main structure\n",
    "        str_pdb = glob(f\"pdb_str/{s}.pdb\")[0]\n",
    "        lsDNA_pdb = str_pdb.replace(\"pdb_str\", \"results_listDNA\")\\\n",
    "                                .replace(\"pdb\", \"list\")\n",
    "        if not os.path.exists(lsDNA_pdb):\n",
    "            mol = molecule.load(\"pdb\", str_pdb)\n",
    "             ##!! Sidechain/base selection\n",
    "            sel = atomsel(\"(within 5 of protein) and nucleic and altloc 'A' '' ' ' and not name OP1 C5' OP2 C3' O5' C1' O4' O3' C4' C2' P\", mol)\n",
    "            with open(lsDNA_pdb, \"w\") as f:\n",
    "                for i,j,k in sorted(uniq(list(zip(sel.chain, sel.resid, [r[1:] if r[0] == \"D\" else r for r in sel.resname]))), key = lambda x:(x[0], x[1])):\n",
    "                    f.write(str(i)+\"\\t\"+str(j)+\"\\t\"+str(k)+\"\\n\")\n",
    "            molecule.delete(mol)        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(s, e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Analyse main str and bio-ass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2223a44c4fae4d0fadd401bf92823984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ssDNA_dict = {}\n",
    "min_ssDNA_length = 4\n",
    "\n",
    "for s in tqdm(protein_with_dna):\n",
    "#     ssDNA[s] = []\n",
    "    try:\n",
    "        # find pair analysis\n",
    "        fp_main = open(f\"results_findPair/{s}.fp\").read()\n",
    "\n",
    "        # Replace \"same chain\"interactions\n",
    "        fp_main = [line for line in fp_main.split(\"\\n\") if len(re.findall(\">(.):.+(\\*\\*).+:(.)<\", line)) == 0]\n",
    "        fp_main = \"\\n\".join(fp_main)\n",
    "#         \"\\n\".join([line for line in fp_main.split(\"\\n\") if ((re.findall(\">(.):\", line) != re.findall(\":(.)<\", line)) and (len(re.findall(\">(.):.+(\\*\\*).+:(.)<\", fp_main)) == 0) )])\n",
    "        \n",
    "        fp_bio  = [open(sb).read() for sb in sorted(glob(f\"results_findPair/{s}.fp[0-9]\"))]\n",
    "        lst_bp_main =  re.findall(\">(.):\\.*([\\-0-9]+).:\", fp_main)+ [(i[1], i[0]) for i in re.findall(\":\\.*([\\-0-9]+).:(.)<\", fp_main)]\n",
    "        lst_bp_bio  = [re.findall(\">(.):\\.*([\\-0-9]+).:\", fb)      + [(i[1], i[0]) for i in re.findall(\":\\.*([\\-0-9]+).:(.)<\", fb)] for fb in fp_bio]\n",
    "        #s If they are double stranded in at least one of the structure (main or bio-assembly)\n",
    "        lst_bp = uniq(lst_bp_main + list(chain.from_iterable(lst_bp_bio)))\n",
    "        \n",
    "        # All DNA residues analysis\n",
    "        ld = open(f\"results_listDNA/{s}.list\").read()\n",
    "        ld = [(i.split(\"\\t\")[0], i.split(\"\\t\")[1]) for i in ld.split(\"\\n\") if i != \"\"]\n",
    "        \n",
    "        # DNA residues not in double strand => ssDNA\n",
    "        ssDNA = set(ld) - set(lst_bp)\n",
    "        \n",
    "        # List ssDNA chains\n",
    "        ssDNA_ch = {i[0]:sorted([int(j[1]) for j in ssDNA if j[0] == i[0]]) for i in ssDNA}\n",
    "        # Check for length\n",
    "        ssDNA_cons = {k:get_consecutive_elements(v) for k,v in ssDNA_ch.items()}\n",
    "        ssDNA_cons = {k:[i for i in v if len(i) >= min_ssDNA_length] for k,v in ssDNA_cons.items()}\n",
    "        ssDNA_cons = {k:v for k,v in ssDNA_cons.items() if len(v) > 0}\n",
    "        \n",
    "        ## ## ##\n",
    "        if len(ssDNA_cons) > 0:\n",
    "            ssDNA_dict[s] = ssDNA_cons\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(s, e)\n",
    "        print(e.with_traceback())\n",
    "        continue\n",
    "    if True:\n",
    "        pass\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Find protein interacting chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ae6edd50724f51883748cba3f24f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/317 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "protein_to_DNA_interactions = pd.DataFrame(columns = [\"structureId\", \"chainId\", \"int_ssDNA_chain\", \"ssDNA_int\"])\n",
    "row_count = 0\n",
    "\n",
    "for s, inter in tqdm(ssDNA_dict.items()):\n",
    "    \n",
    "    sel_list = [[\"protein and within 5 of (chain '\"+ss_chain +\"' and resid \"+ ' '.join(map(lambda x: \"'\"+str(x)+\"'\", sub_ss_int)) +\")\", ss_chain, sub_ss_int]\n",
    "                        for ss_chain, ss_int in inter.items()\n",
    "                        for sub_ss_int in ss_int]\n",
    "    mol = molecule.load(\"pdb\", f\"pdb_str/{s}.pdb\")\n",
    "    \n",
    "    prot_int = []\n",
    "    # Find protein chains close to the ssDNA\n",
    "    for sel_txt, dna_ch, dna_inter in sel_list:\n",
    "        try:\n",
    "            sel = atomsel(sel_txt, mol)\n",
    "        except Exception as e:\n",
    "            print(s, e)\n",
    "        prot_int.append([dna_ch, dna_inter, uniq(sel.chain)])\n",
    "    \n",
    "    # For each previously found protein chain, find consecutive interacting NA chains longer than 4 residues\n",
    "    for dna_ch, dna_int, prot_ch in prot_int:\n",
    "        for ch in prot_ch:\n",
    "            if ch == dna_ch:\n",
    "                print(s, dna_ch, ch)\n",
    "            sel_txt = \"chain '\" + dna_ch + \"' and resid \" + \" \".join(map(lambda x: \"'\"+str(x)+\"'\", dna_int)) + \" and (within 5 of chain '\" + ch + \"')\"\n",
    "            sel = atomsel(sel_txt)\n",
    "            \n",
    "            cons_dna = get_consecutive_elements(sorted(uniq(sel.resid)))\n",
    "            cons_dna = [i for i in cons_dna if len(i) >= min_ssDNA_length]\n",
    "            if len(cons_dna) == 1:\n",
    "                pass\n",
    "            elif len(cons_dna) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                new_cons = [cons_dna[0]]\n",
    "                for l0, l1 in zip(cons_dna[:-1], cons_dna[1:]):\n",
    "                    # If a 1-gap is found, fill it\n",
    "                    if l1[0]-l0[-1] == 2:\n",
    "                        new_cons[-1] = new_cons[-1]+[l1[0]-1]+l1\n",
    "                    else:\n",
    "                        new_cons.append(l1)\n",
    "                cons_dna = new_cons\n",
    "            \n",
    "            # Update Dataframe\n",
    "            protein_to_DNA_interactions.loc[row_count]=[s.upper(), ch, dna_ch, str(cons_dna)]\n",
    "            row_count += 1\n",
    "    \n",
    "    molecule.delete(mol)\n",
    "protein_to_DNA_interactions.to_csv(\"./csv_tables/df_protein_dna_interaction.csv\", float_format='%.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bound_pdb_chains = uniq([i+\".\"+j for i,j in zip(protein_to_DNA_interactions.structureId, protein_to_DNA_interactions.chainId)])\n",
    "len(bound_pdb_chains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Complete ssDNA-protein interactions table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "protein_to_DNA_interactions = pd.read_csv(\"./csv_tables/df_protein_dna_interaction.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "q=\"\"\"{entries(entry_ids:[\\\"\"\"\"+\"\\\",\\\"\".join(uniq(protein_to_DNA_interactions.structureId))+\"\"\"\\\"]){rcsb_id,struct_keywords{pdbx_keywords}exptl{method}polymer_entities{entity_poly{type}rcsb_cluster_membership{cluster_id,identity}rcsb_polymer_entity_container_identifiers {auth_asym_ids}}}}\"\"\"\n",
    "response = urllib.request.urlopen(\"https://data.rcsb.org/graphql?query=\" + urllib.parse.quote(q.replace(\"\\n\", \"\").replace(\" \", \"\")))\n",
    "r = response.read().decode(\"utf-8\")\n",
    "j = json.loads(r)\n",
    "j = j[\"data\"][\"entries\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in j:    \n",
    "    exp_met = i['exptl'][0][\"method\"]\n",
    "    desc = i['struct_keywords'][\"pdbx_keywords\"]\n",
    "    try:\n",
    "        for k in i['polymer_entities']:\n",
    "            entity_type = k[\"entity_poly\"][\"type\"]\n",
    "            if \"polypeptide\" in entity_type:\n",
    "#                 print(\"k\", k)\n",
    "                for l in k[\"rcsb_cluster_membership\"]:\n",
    "                    if l[\"identity\"] == 100:\n",
    "                        for c in k[\"rcsb_polymer_entity_container_identifiers\"][\"auth_asym_ids\"]:\n",
    "                            data.append([i[\"rcsb_id\"], c, l['cluster_id'], entity_type, exp_met, desc])\n",
    "    except:\n",
    "        continue\n",
    "prot_to_dna_info = pd.DataFrame(data, columns=[\"structureId\", \"chainId\", \"clusterNumber100\", \"entity_type\", \"experimentalTechnique\", \"classification\"])\n",
    "prot_to_dna_info.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_prot_to_dna_info = protein_to_DNA_interactions.merge(prot_to_dna_info, left_on = [\"structureId\", \"chainId\"], right_on = [\"structureId\", \"chainId\"])\n",
    "only_interactions = df_prot_to_dna_info[[\"structureId\", \"chainId\", \"int_ssDNA_chain\", \"ssDNA_int\"]]\n",
    "df_with_ssdna = df_prot_to_dna_info[[\"structureId\", \"chainId\", \"clusterNumber100\", \"experimentalTechnique\", \"classification\"]]\n",
    "df_with_ssdna = df_with_ssdna.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "only_interactions.to_csv(\"csv_tables/ssDNA_interacting.csv\", float_format='%.1f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Save ssDNA + protein chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>structureId</th>\n",
       "      <th>chainId</th>\n",
       "      <th>int_ssDNA_chain</th>\n",
       "      <th>ssDNA_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4A8Q</td>\n",
       "      <td>C</td>\n",
       "      <td>H</td>\n",
       "      <td>[[3, 4, 5, 6]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6F2S</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "      <td>[[3, 4, 5, 6, 7]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6F2S</td>\n",
       "      <td>E</td>\n",
       "      <td>O</td>\n",
       "      <td>[[3, 4, 5, 6, 7]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6F2S</td>\n",
       "      <td>H</td>\n",
       "      <td>S</td>\n",
       "      <td>[[3, 4, 5, 6]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6F2S</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>[[3, 4, 5, 6]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>4TU9</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>[[3, 4, 5, 6]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>4TU9</td>\n",
       "      <td>B</td>\n",
       "      <td>P</td>\n",
       "      <td>[[1, 2, 3, 4, 5, 6]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>4TU9</td>\n",
       "      <td>A</td>\n",
       "      <td>P</td>\n",
       "      <td>[[3, 4, 5, 6]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>2ES2</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>[[2, 3, 4, 5]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>4FM2</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>[[3, 4, 5, 6, 7]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>633 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    structureId chainId int_ssDNA_chain             ssDNA_int\n",
       "0          4A8Q       C               H        [[3, 4, 5, 6]]\n",
       "1          6F2S       F               P     [[3, 4, 5, 6, 7]]\n",
       "2          6F2S       E               O     [[3, 4, 5, 6, 7]]\n",
       "3          6F2S       H               S        [[3, 4, 5, 6]]\n",
       "4          6F2S       I               S        [[3, 4, 5, 6]]\n",
       "..          ...     ...             ...                   ...\n",
       "628        4TU9       B               E        [[3, 4, 5, 6]]\n",
       "629        4TU9       B               P  [[1, 2, 3, 4, 5, 6]]\n",
       "630        4TU9       A               P        [[3, 4, 5, 6]]\n",
       "631        2ES2       A               B        [[2, 3, 4, 5]]\n",
       "632        4FM2       A               T     [[3, 4, 5, 6, 7]]\n",
       "\n",
       "[633 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e09a1bd58a6468b9343320b472e1cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_line_description(line):\n",
    "    return line[12:16] + \" \" + line[17:20] + \" \" + line[22:26]\n",
    "\n",
    "for mol in molecule.listall():\n",
    "    molecule.delete(mol)\n",
    "    \n",
    "for i, (s, pc, dc, _) in tqdm(only_interactions.iterrows(), total = len(only_interactions)):\n",
    "    s = s.lower()\n",
    "    chain_name = f\"pdb_ssDNAProtChains/{s}_{pc}_{dc}.pdb\"\n",
    "    if os.path.exists(chain_name):\n",
    "        continue\n",
    "    \n",
    "    mol = molecule.load(\"pdb\", f\"./pdb_str/{s}.pdb\")\n",
    "    sel = atomsel(f\"noh and chain {pc} {dc}\")\n",
    "    \n",
    "    sel.write(\"pdb\", chain_name)\n",
    "    \n",
    "    molecule.delete(mol)\n",
    "    \n",
    "        #Delete duplicate lines (~Altloc)\n",
    "    pdb_content = open(chain_name, \"r\").read().split(\"\\n\")\n",
    "    for line in range(len(pdb_content)-1, 0, -1):\n",
    "        if get_line_description(pdb_content[line]) == get_line_description(pdb_content[line-1]):\n",
    "            del(pdb_content[line])\n",
    "    open(chain_name, \"w\").write(\"\\n\".join(pdb_content))\n",
    "    \n",
    "    #Add missing atoms, remove water, ...\n",
    "#     try:\n",
    "#         fix = pdbfixer.PDBFixer(filename=chain_name)\n",
    "#         fix.findMissingResidues()\n",
    "#         fix.findMissingAtoms()\n",
    "#         fix.addMissingAtoms()\n",
    "#         fix.removeHeterogens(keepWater=False)\n",
    "#         fix.topology.createStandardBonds()\n",
    "#         PDBFile.writeFile(fix.topology, fix.positions, open(chain_name, 'w'), keepIds = True)\n",
    "#     except:\n",
    "#         print(\"PDB fix err.\", chain_name)\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Make tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Merge Bound structures by cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_bound = pd.DataFrame(columns=[f\"clusterNumber{clusterNumber}\",'boundId','bound_TechExp','bound_class'])\n",
    "clusters_bound = map(np.int64, sorted(map(int, uniq(df_with_ssdna[f\"clusterNumber{clusterNumber}\"]))))\n",
    "\n",
    "for cluster in clusters_bound:\n",
    "    pd_bound_cluster = df_with_ssdna[df_with_ssdna[f\"clusterNumber{clusterNumber}\"] == cluster]\n",
    "    bound_id_ch = [i+\"_\"+j for i, j in zip(pd_bound_cluster.structureId, pd_bound_cluster.chainId)]\n",
    "    bound_techExp = uniq([i for i in pd_bound_cluster.experimentalTechnique])\n",
    "    bound_class = uniq([i.lower() for i in pd_bound_cluster.classification])\n",
    "    \n",
    "    df_bound = df_bound.append({f\"clusterNumber{clusterNumber}\":cluster,\n",
    "                                 'boundId':\" \".join(bound_id_ch),\n",
    "                                 'bound_TechExp':\", \".join(bound_techExp),\n",
    "                                 'bound_class':\", \".join(bound_class)\n",
    "                               }, \n",
    "                               ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clusterNumber100</th>\n",
       "      <th>boundId</th>\n",
       "      <th>bound_TechExp</th>\n",
       "      <th>bound_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118</td>\n",
       "      <td>1RCN_E</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>hydrolase/dna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>6N4C_C 6GH5_C 6XL5_C 6PST_I 3IYD_C 6XH7_C 7C17...</td>\n",
       "      <td>ELECTRON MICROSCOPY</td>\n",
       "      <td>transcription, transferase/dna, transcription,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153</td>\n",
       "      <td>6GH5_D 6XL5_D 3IYD_D 6Z9T_Y 6GFW_D</td>\n",
       "      <td>ELECTRON MICROSCOPY</td>\n",
       "      <td>transcription, transferase/dna, transcription,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161</td>\n",
       "      <td>7NKY_B</td>\n",
       "      <td>ELECTRON MICROSCOPY</td>\n",
       "      <td>transcription</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>207</td>\n",
       "      <td>2AGP_A</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>transferase/dna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>95414</td>\n",
       "      <td>6RWL_F</td>\n",
       "      <td>ELECTRON MICROSCOPY</td>\n",
       "      <td>recombination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>98924</td>\n",
       "      <td>5VI5_C</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>transcription</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>100737</td>\n",
       "      <td>6DG0_A 6DG0_B</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>rna binding protein/dna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>101742</td>\n",
       "      <td>6BUX_A</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>hydrolase/dna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>102672</td>\n",
       "      <td>5V9X_A</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>hydrolase/dna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    clusterNumber100                                            boundId  \\\n",
       "0                118                                             1RCN_E   \n",
       "1                144  6N4C_C 6GH5_C 6XL5_C 6PST_I 3IYD_C 6XH7_C 7C17...   \n",
       "2                153                 6GH5_D 6XL5_D 3IYD_D 6Z9T_Y 6GFW_D   \n",
       "3                161                                             7NKY_B   \n",
       "4                207                                             2AGP_A   \n",
       "..               ...                                                ...   \n",
       "204            95414                                             6RWL_F   \n",
       "205            98924                                             5VI5_C   \n",
       "206           100737                                      6DG0_A 6DG0_B   \n",
       "207           101742                                             6BUX_A   \n",
       "208           102672                                             5V9X_A   \n",
       "\n",
       "           bound_TechExp                                        bound_class  \n",
       "0      X-RAY DIFFRACTION                                      hydrolase/dna  \n",
       "1    ELECTRON MICROSCOPY  transcription, transferase/dna, transcription,...  \n",
       "2    ELECTRON MICROSCOPY  transcription, transferase/dna, transcription,...  \n",
       "3    ELECTRON MICROSCOPY                                      transcription  \n",
       "4      X-RAY DIFFRACTION                                    transferase/dna  \n",
       "..                   ...                                                ...  \n",
       "204  ELECTRON MICROSCOPY                                      recombination  \n",
       "205    X-RAY DIFFRACTION                                      transcription  \n",
       "206    X-RAY DIFFRACTION                            rna binding protein/dna  \n",
       "207    X-RAY DIFFRACTION                                      hydrolase/dna  \n",
       "208    X-RAY DIFFRACTION                                      hydrolase/dna  \n",
       "\n",
       "[209 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Add unbound structures by cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2565cd1564443edbd1178e18700a51f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/209 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_cluster_by_id(cluster_id:int):\n",
    "    \"\"\"\n",
    "    cluster_id : ID of the wanted cluster\n",
    "    return : \n",
    "        \"structure.chain\" list in the cluster\n",
    "    \"\"\"\n",
    "    q1 = Attr('rcsb_cluster_membership.cluster_id').equals(int(cluster_id))\n",
    "    q2 = Attr('rcsb_cluster_membership.identity').equals(100)\n",
    "    q = q1 & q2\n",
    "    r = list(set(q(\"polymer_instance\")))\n",
    "    return r\n",
    "\n",
    "protein_without_dna = set(protein_without_dna)\n",
    "df_bound_unbound = df_bound.copy()\n",
    "df_bound_unbound[\"unboundId\"] = [\"\" for i in range(len(df_bound_unbound))]\n",
    "\n",
    "# For each cluster in the dataframe...\n",
    "for i, r in tqdm(df_bound_unbound.iterrows(), total = len(df_bound_unbound)):\n",
    "    (cl, b, b_ET, b_class, ub) = r\n",
    "    b_for_query = b.split(\" \")[0].replace(\"_\", \".\")\n",
    "    \n",
    "    cl_pdb_ch = get_cluster_by_id(cl)\n",
    "    ub_pdb_ch = [s.replace(\".\", \"_\") for s in cl_pdb_ch if s[:4] in protein_without_dna]\n",
    "    \n",
    "    df_bound_unbound.iloc[i][\"unboundId\"] = \" \".join(ub_pdb_ch)\n",
    "\n",
    "df_bound_unbound.replace('', np.nan, inplace=True)\n",
    "df_bound_unbound.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bound_unbound.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Convert unbound chains into author's chains\n",
    "There is some discrepancy between the two id (Auth. 1RCN_E = 1RCN.B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ub_q = \"\\\"\"+\"\\\",\\\"\".join(df_bound_unbound[\"unboundId\"]).replace(\"_\", \".\").replace(\" \", \"\\\",\\\"\") + \"\\\"\"\n",
    "q=\"\"\"{polymer_entity_instances(instance_ids: [\"\"\" + ub_q+ \"\"\"]) {rcsb_id,rcsb_polymer_entity_instance_container_identifiers {auth_asym_id}}}\"\"\"\n",
    "response = urllib.request.urlopen(\"https://data.rcsb.org/graphql?query=\" + urllib.parse.quote(q.replace(\"\\n\", \"\").replace(\" \", \"\")))\n",
    "r = response.read().decode(\"utf-8\")\n",
    "j = json.loads(r)\n",
    "j = j[\"data\"][\"polymer_entity_instances\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "id_to_authId = {}\n",
    "\n",
    "for i in j:\n",
    "    rcsb_id = i[\"rcsb_id\"].split(\".\")[0]\n",
    "    rcsb_ch = i[\"rcsb_id\"].split(\".\")[-1]\n",
    "    auth_id = i[\"rcsb_polymer_entity_instance_container_identifiers\"][\"auth_asym_id\"]\n",
    "    \n",
    "    if rcsb_ch != auth_id:\n",
    "        id_to_authId[rcsb_id+\"_\"+rcsb_ch] = rcsb_id+\".\"+auth_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af42a7d8cfe49a78256d8fe179b25d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dominique/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for k,v in tqdm(id_to_authId.items()):\n",
    "    df_bound_unbound[\"unboundId\"] = df_bound_unbound[\"unboundId\"].str.replace(k,v)\n",
    "\n",
    "df_bound_unbound[\"unboundId\"] = df_bound_unbound[\"unboundId\"].str.replace(\".\",\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clusterNumber100</th>\n",
       "      <th>boundId</th>\n",
       "      <th>bound_TechExp</th>\n",
       "      <th>bound_class</th>\n",
       "      <th>unboundId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [clusterNumber100, boundId, bound_TechExp, bound_class, unboundId]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bound_unbound[df_bound_unbound.clusterNumber100 == 5616]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bound_unbound.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<!-- ## Bound/unbound table : merge bound and unbound lists -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Add unbound experimental info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "all_unbound = \" \".join(df_bound_unbound.unboundId).replace(\"_\", \".\").split(\" \")\n",
    "all_unbound = uniq([i[:4] for i in all_unbound])\n",
    "ub_q = \"\\\"\"+\"\\\",\\\"\".join(all_unbound) + \"\\\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "q = \"\"\"{entries(entry_ids: [\"\"\" + ub_q+ \"\"\"]) {rcsb_id,struct_keywords {pdbx_keywords}exptl {method}}}\n",
    "\"\"\"\n",
    "response = urllib.request.urlopen(\"https://data.rcsb.org/graphql?query=\" + urllib.parse.quote(q.replace(\"\\n\", \"\").replace(\" \", \"\")))\n",
    "r = response.read().decode(\"utf-8\")\n",
    "j = json.loads(r)\n",
    "j = j[\"data\"][\"entries\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "meth_dict = {}\n",
    "desc_dict = {}\n",
    "\n",
    "for entry in j:\n",
    "    pdb_id = entry[\"rcsb_id\"]\n",
    "    desc = entry[\"struct_keywords\"][\"pdbx_keywords\"]\n",
    "    meth = entry[\"exptl\"][0][\"method\"]\n",
    "    meth_dict[pdb_id] = meth\n",
    "    desc_dict[pdb_id] = desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c392c4d7be42339e6b262a9185026d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_bound_unbound[\"unbound_TechExp\"] = [\"\" for i in range(len(df_bound_unbound))]\n",
    "df_bound_unbound[\"unbound_class\"] = [\"\" for i in range(len(df_bound_unbound))]\n",
    "\n",
    "unbound_TechExp = []\n",
    "unbound_class = []\n",
    "\n",
    "for i, r in tqdm(df_bound_unbound.iterrows(), total = len(df_bound_unbound)):\n",
    "    unbound_pdb = uniq([v[:4] for v in r.unboundId.split(\" \")])\n",
    "    \n",
    "    meth = uniq([meth_dict[pdb].upper() for pdb in unbound_pdb])\n",
    "    desc = uniq([desc_dict[pdb].lower() for pdb in unbound_pdb])\n",
    "    \n",
    "    try:\n",
    "        unbound_TechExp.append(\" \".join(meth))\n",
    "        unbound_class.append(\" \".join(desc))\n",
    "    except Exception as e:\n",
    "        print(e, i)\n",
    "df_bound_unbound[\"unbound_TechExp\"] = unbound_TechExp\n",
    "df_bound_unbound[\"unbound_class\"] = unbound_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Merge functional classifications\n",
    "b_class = df_bound_unbound.bound_class\n",
    "ub_class = df_bound_unbound.unbound_class\n",
    "merge_class = [i+\",\"+j for i, j in zip(b_class, ub_class)]\n",
    "merge_class = [i.split(\",\") for i in merge_class]\n",
    "merge_class = [\",\".join(uniq(i)) for i in merge_class]\n",
    "df_bound_unbound[\"classification\"] = merge_class\n",
    "# clean\n",
    "df_bound_unbound = df_bound_unbound[[\"clusterNumber100\",\"boundId\",\"unboundId\",\"bound_TechExp\",\"unbound_TechExp\",\"classification\"]]\n",
    "# df_bound_unbound = df_bound_unbound.rename(columns={\"unboundId_x\":\"unboundId\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clusterNumber100</th>\n",
       "      <th>boundId</th>\n",
       "      <th>unboundId</th>\n",
       "      <th>bound_TechExp</th>\n",
       "      <th>unbound_TechExp</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118</td>\n",
       "      <td>1RCN_E</td>\n",
       "      <td>4OT4_B 1A2W_A 1RNU_A 3LXO_A 1RNO_A 1WBU_B 1RNW...</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>X-RAY DIFFRACTION NEUTRON DIFFRACTION</td>\n",
       "      <td>hydrolase/dna,rna) hydrolase(phosphoric dieste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>6N4C_C 6GH5_C 6XL5_C 6PST_I 3IYD_C 6XH7_C 7C17...</td>\n",
       "      <td>4KN7_C 6PSS_I 4JKR_I 5VT0_I 4LK1_I 5W1S_I 4XSX...</td>\n",
       "      <td>ELECTRON MICROSCOPY</td>\n",
       "      <td>X-RAY DIFFRACTION ELECTRON MICROSCOPY</td>\n",
       "      <td>transcription/dna, transcription, transferase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153</td>\n",
       "      <td>6GH5_D 6XL5_D 3IYD_D 6Z9T_Y 6GFW_D</td>\n",
       "      <td>4LLG_J 3LU0_D 4LK0_J 5TBZ_I 5W1S_J 6WMU_D 4LK0...</td>\n",
       "      <td>ELECTRON MICROSCOPY</td>\n",
       "      <td>X-RAY DIFFRACTION ELECTRON MICROSCOPY</td>\n",
       "      <td>transcription/dna, transcription, transferase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161</td>\n",
       "      <td>7NKY_B</td>\n",
       "      <td>1I50_B 4BBR_B 1SFO_B 1NIK_B 1TWA_B 3QT1_B 3RZD...</td>\n",
       "      <td>ELECTRON MICROSCOPY</td>\n",
       "      <td>X-RAY DIFFRACTION ELECTRON MICROSCOPY</td>\n",
       "      <td>transferase transferase, transcription, trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>207</td>\n",
       "      <td>2AGP_A</td>\n",
       "      <td>2W9A_A 2W8K_A 3FDS_A 2W9B_B 2RDJ_B 2W9C_B 2W8L...</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>transferase/dna,transferase transferase/dna dn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>32559</td>\n",
       "      <td>1ZVV_B 1ZVV_A 1ZVV_G</td>\n",
       "      <td>2JCG_A</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>transcription,transcription/dna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>33173</td>\n",
       "      <td>3UDG_A 3UDG_C 3UDG_B</td>\n",
       "      <td>1SE8_A</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>dna binding protein,dna binding protein/dna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>34877</td>\n",
       "      <td>7CSZ_A</td>\n",
       "      <td>7CSX_A</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>rna binding protein/dna,rna binding protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>36247</td>\n",
       "      <td>2CCZ_A</td>\n",
       "      <td>1V1Q_A 1V1Q_B</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>dna/replication,dna binding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>37050</td>\n",
       "      <td>5ODL_A</td>\n",
       "      <td>5ODK_B 5ODK_A 5ODK_C</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>dna binding protein</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     clusterNumber100                                            boundId  \\\n",
       "0                 118                                             1RCN_E   \n",
       "1                 144  6N4C_C 6GH5_C 6XL5_C 6PST_I 3IYD_C 6XH7_C 7C17...   \n",
       "2                 153                 6GH5_D 6XL5_D 3IYD_D 6Z9T_Y 6GFW_D   \n",
       "3                 161                                             7NKY_B   \n",
       "4                 207                                             2AGP_A   \n",
       "..                ...                                                ...   \n",
       "139             32559                               1ZVV_B 1ZVV_A 1ZVV_G   \n",
       "141             33173                               3UDG_A 3UDG_C 3UDG_B   \n",
       "148             34877                                             7CSZ_A   \n",
       "149             36247                                             2CCZ_A   \n",
       "151             37050                                             5ODL_A   \n",
       "\n",
       "                                             unboundId        bound_TechExp  \\\n",
       "0    4OT4_B 1A2W_A 1RNU_A 3LXO_A 1RNO_A 1WBU_B 1RNW...    X-RAY DIFFRACTION   \n",
       "1    4KN7_C 6PSS_I 4JKR_I 5VT0_I 4LK1_I 5W1S_I 4XSX...  ELECTRON MICROSCOPY   \n",
       "2    4LLG_J 3LU0_D 4LK0_J 5TBZ_I 5W1S_J 6WMU_D 4LK0...  ELECTRON MICROSCOPY   \n",
       "3    1I50_B 4BBR_B 1SFO_B 1NIK_B 1TWA_B 3QT1_B 3RZD...  ELECTRON MICROSCOPY   \n",
       "4    2W9A_A 2W8K_A 3FDS_A 2W9B_B 2RDJ_B 2W9C_B 2W8L...    X-RAY DIFFRACTION   \n",
       "..                                                 ...                  ...   \n",
       "139                                             2JCG_A    X-RAY DIFFRACTION   \n",
       "141                                             1SE8_A    X-RAY DIFFRACTION   \n",
       "148                                             7CSX_A    X-RAY DIFFRACTION   \n",
       "149                                      1V1Q_A 1V1Q_B    X-RAY DIFFRACTION   \n",
       "151                               5ODK_B 5ODK_A 5ODK_C    X-RAY DIFFRACTION   \n",
       "\n",
       "                           unbound_TechExp  \\\n",
       "0    X-RAY DIFFRACTION NEUTRON DIFFRACTION   \n",
       "1    X-RAY DIFFRACTION ELECTRON MICROSCOPY   \n",
       "2    X-RAY DIFFRACTION ELECTRON MICROSCOPY   \n",
       "3    X-RAY DIFFRACTION ELECTRON MICROSCOPY   \n",
       "4                        X-RAY DIFFRACTION   \n",
       "..                                     ...   \n",
       "139                      X-RAY DIFFRACTION   \n",
       "141                      X-RAY DIFFRACTION   \n",
       "148                      X-RAY DIFFRACTION   \n",
       "149                      X-RAY DIFFRACTION   \n",
       "151                      X-RAY DIFFRACTION   \n",
       "\n",
       "                                        classification  \n",
       "0    hydrolase/dna,rna) hydrolase(phosphoric dieste...  \n",
       "1     transcription/dna, transcription, transferase...  \n",
       "2     transcription/dna, transcription, transferase...  \n",
       "3     transferase transferase, transcription, trans...  \n",
       "4    transferase/dna,transferase transferase/dna dn...  \n",
       "..                                                 ...  \n",
       "139                    transcription,transcription/dna  \n",
       "141        dna binding protein,dna binding protein/dna  \n",
       "148        rna binding protein/dna,rna binding protein  \n",
       "149                        dna/replication,dna binding  \n",
       "151                                dna binding protein  \n",
       "\n",
       "[105 rows x 6 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bound_unbound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "# FATCAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Download unbound structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c390fcabc9c54bceb894d5eebf3dcd25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/492 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_unbound = uniq([j[:4] for i in df_bound_unbound.unboundId for j in i.split(\" \")])\n",
    "failed_dl = []\n",
    "\n",
    "def dl_str(f):\n",
    "    ####\n",
    "    if os.path.exists(f\"pdb_str/{f}.pdb\"):\n",
    "        return\n",
    "    ####\n",
    "    url = f\"https://files.rcsb.org/download/{f}.pdb\"\n",
    "    success = download_file(url, f\"pdb_str/{f.lower()}.pdb\")\n",
    "    if success == False:\n",
    "#         print(f)\n",
    "        failed_dl.append(f)\n",
    "    \n",
    "# Run 5 multiple threads. Each call will take the next element in urls list\n",
    "results = ThreadPool(50).imap_unordered(dl_str, all_unbound)\n",
    "for r in tqdm(results, total = len(all_unbound)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Prepare files to compute RMSD : split PDB for chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                 1RCN_E\n",
       "1      6N4C_C 6GH5_C 6XL5_C 6PST_I 3IYD_C 6XH7_C 7C17...\n",
       "2                     6GH5_D 6XL5_D 3IYD_D 6Z9T_Y 6GFW_D\n",
       "3                                                 7NKY_B\n",
       "4                                                 2AGP_A\n",
       "                             ...                        \n",
       "139                                 1ZVV_B 1ZVV_A 1ZVV_G\n",
       "141                                 3UDG_A 3UDG_C 3UDG_B\n",
       "148                                               7CSZ_A\n",
       "149                                               2CCZ_A\n",
       "151                                               5ODL_A\n",
       "Name: boundId, Length: 105, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bound_unbound.boundId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35dd9af57a140f5a69300dcf0031276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1327 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_line_description(line):\n",
    "    return line[12:16] + \" \" + line[17:20] + \" \" + line[22:26]\n",
    "\n",
    "failed_split = []\n",
    "    \n",
    "all_unbound = uniq([j for i in df_bound_unbound.unboundId for j in i.split(\" \")])\n",
    "all_bound = uniq([j for i in df_bound_unbound.boundId for j in i.split(\" \")])\n",
    "# Save only the chains\n",
    "total = len(all_unbound)\n",
    "for s in tqdm(all_bound + all_unbound):\n",
    "    sl = s.lower()\n",
    "    chain_name = f\"./pdb_chains/{sl}.pdb\"\n",
    "    \n",
    "    if os.path.exists(chain_name):\n",
    "        continue\n",
    "    try:\n",
    "        mol = molecule.load(\"pdb\", f\"pdb_str/{sl[:4]}.pdb\")\n",
    "    except Exception as e:\n",
    "#         print(e)\n",
    "        failed_split.append(sl[:4])\n",
    "        continue\n",
    "    sel = atomsel(f\"noh and chain '{s[5:]}'\", mol)\n",
    "    sel.write(\"pdb\", chain_name)\n",
    "    molecule.delete(mol)\n",
    "\n",
    "    #Delete duplicate lines (~Altloc)\n",
    "    pdb_content = open(chain_name, \"r\").read().split(\"\\n\")\n",
    "    for line in range(len(pdb_content)-1, 0, -1):\n",
    "        if get_line_description(pdb_content[line]) == get_line_description(pdb_content[line-1]):\n",
    "            del(pdb_content[line])\n",
    "    open(chain_name, \"w\").write(\"\\n\".join(pdb_content))\n",
    "    \n",
    "    #Add missing atoms, remove water, ...\n",
    "    try:\n",
    "        fix = pdbfixer.PDBFixer(filename=chain_name)\n",
    "        fix.findMissingResidues()\n",
    "        fix.findMissingAtoms()\n",
    "        fix.addMissingAtoms()\n",
    "        fix.removeHeterogens(keepWater=False)\n",
    "        fix.topology.createStandardBonds()\n",
    "        PDBFile.writeFile(fix.topology, fix.positions, open(chain_name, 'w'), keepIds = True)\n",
    "    except:\n",
    "        print(\"PDB fix err.\", chain_name)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "failed_split = uniq(failed_split)\n",
    "failed_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Interlude : remove failed split from tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def remove_failed(cell, failed_split):\n",
    "    for s in cell.split(\" \"):\n",
    "        if s[:4].lower() in failed_split:\n",
    "            cell = cell.replace(s, \"\")\n",
    "            cell = cell.replace(\"  \", \" \")\n",
    "            if cell[0] == \" \":\n",
    "                cell = cell[1:]\n",
    "            if cell[-1] == \" \":\n",
    "                cell = cell[:-1]\n",
    "    return cell\n",
    "\n",
    "for i, r in df_bound_unbound.iterrows():\n",
    "    b = r.boundId\n",
    "    ub = r.unboundId\n",
    "    \n",
    "\n",
    "    df_bound_unbound.loc[i].boundId = remove_failed(b, failed_split)\n",
    "    df_bound_unbound.loc[i].unboundId = remove_failed(ub, failed_split)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Prepare command to compute RMSD using FATCAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "FATCAT_PATH = \"./utils/FATCAT/FATCATMain/FATCAT\"\n",
    "# fatcat_out = open(\"./fatcat_out.txt\", \"a\")\n",
    "list_of_commands = \"\"\n",
    "count = 0\n",
    "\n",
    "for r in tqdm(df_bound_unbound.iterrows(), total = len(df_bound_unbound)):\n",
    "    bound = r[1].boundId.split(\" \")\n",
    "    unbound = r[1].unboundId.split(\" \")\n",
    "    \n",
    "    all_ch = sorted(bound+unbound)\n",
    "    for i1,j1 in enumerate(all_ch[:]):\n",
    "        for i2,j2 in enumerate(all_ch[i1:]):\n",
    "            if j1[:4] in failed_split or j2[:4] in failed_split:\n",
    "                continue\n",
    "            count += 1\n",
    "            # Do FATCAT\n",
    "            list_of_commands += f\"{FATCAT_PATH} -o results_fatcat/{j1.lower()}_{j2.lower()} -p1 {j1.lower()}.pdb -p2 {j2.lower()}.pdb -i ./pdb_chains -r -q -c\\n\"\n",
    "\n",
    "print(count)\n",
    "open(\"./fatcat_commands.txt\", \"w\").write(list_of_commands)\n",
    "\n",
    "df_bound_unbound.to_csv(\"./csv_tables/bound_unbound.preFATCAT.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Run FATCAT"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "%%bash\n",
    "./fatcat_split.sh"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "str1 str2 str1_NbRes str2_NbRes twist? ini-rmsd opt-equ opt-rmsd chain-rmsd score Align-len nb_gaps\n",
    "http://fatcat.godziklab.org/fatcat-cgi/cgi/fatcatHelp.pl\n",
    "\n",
    "-> Keep chain RMSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Super-impose structures in cluster to check interface surface and ssDNA position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Superimpose PDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def read_fatcat_res(i1, i2, fatcat_results):\n",
    "    if f\"./results_fatcat/{i1.lower()}_{i2.lower()}.chain.txt\" in fatcat_results:\n",
    "        radix = f\"{i1.lower()}_{i2.lower()}\"\n",
    "        inv = False\n",
    "    elif f\"./results_fatcat/{i2.lower()}_{i1.lower()}.chain.txt\" in fatcat_results:\n",
    "        radix = f\"{i2.lower()}_{i1.lower()}\"\n",
    "        inv = True\n",
    "    else:\n",
    "        return None, None, None, None\n",
    "    ftr = f\"./results_fatcat/{radix}.chain.txt\"\n",
    "            \n",
    "    with open(ftr, \"r\") as ft:\n",
    "        ftc = ft.read().split(\"\\n\\n\")\n",
    "\n",
    "    afp = ftc[3]\n",
    "    afp = afp.split(\"\\n\")[1:-1]\n",
    "    afp_1 = [l.split(\" \") for l in afp[1::3]]\n",
    "    afp_1 = [int(item) for sublist in afp_1 for item in sublist if item != \"\"]\n",
    "    afp_2 = [l.split(\" \") for l in afp[2::3]]\n",
    "    afp_2 = [int(item) for sublist in afp_2 for item in sublist if item != \"\"]\n",
    "\n",
    "    return afp_1, afp_2, radix, inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fatcat_results = set(glob(\"./results_fatcat/*chain*\"))\n",
    "pdb_chains = glob(f\"./pdb_chains/*\")\n",
    "pdb_ssDNA  = glob(f\"./pdb_ssDNAProtChains/*\")\n",
    "pdb = pdb_chains + pdb_ssDNA\n",
    "\n",
    "only_interactions = pd.read_csv(\"csv_tables/ssDNA_interacting.csv\", index_col = 0)\n",
    "df_bound_unbound = pd.read_csv(\"./csv_tables/bound_unbound.preFATCAT.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "for i,(cl, b,ub,_,_,_,) in tqdm(df_bound_unbound.iterrows(), total = len(df_bound_unbound)):\n",
    "    b = b.split(\" \")\n",
    "    ub = ub.split(\" \")\n",
    "    a = b + ub\n",
    "    \n",
    "    lssDNA = [[j,[k, molecule.load(\"pdb\", k)]] for j in a for k in pdb if ((j.lower() in k) or (f\"{j.lower()[:4]}_{j[5:]}\" in k))]\n",
    "    comb = combinations(lssDNA, 2)\n",
    "    \n",
    "    for (i1, (pdb_1, mol_1)), (i2, (pdb_2, mol_2)) in comb:\n",
    "        afp_1, afp_2, radix, _ = read_fatcat_res(i1, i2, fatcat_results)\n",
    "        if afp_1 is None or afp_2 is None:\n",
    "            continue\n",
    "        sel_1 = atomsel(f\"altloc '' and name CA and resid '\"+\"' '\".join(map(str, afp_1)) + \"'\", mol_1)\n",
    "        sel_2 = atomsel(f\"altloc '' and name CA and resid '\"+\"' '\".join(map(str, afp_2)) + \"'\", mol_2)\n",
    "        if len(sel_1) != len(sel_2) or len(sel_1) == 0:\n",
    "            continue\n",
    "        fit_m = sel_2.fit(sel_1)\n",
    "        sel = atomsel(f\"all\", mol_2)\n",
    "        sel.move(fit_m)\n",
    "        molecule.write(mol_2, \"pdb\", pdb_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Process Fatcat result files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fatcat_results = set(glob(\"./results_fatcat/*chain*\"))\n",
    "df_bound_unbound = pd.read_csv(\"./csv_tables/bound_unbound.preFATCAT.csv\", index_col = 0)\n",
    "dict_fatcat = {}\n",
    "\n",
    "for i,(cl, b,ub, _,_,_,) in tqdm(df_bound_unbound.iterrows(), total = len(df_bound_unbound)):\n",
    "    b = b.split(\" \")\n",
    "    ub = ub.split(\" \")\n",
    "    \n",
    "    for i1 in b+ub:\n",
    "        afp_1, afp_2, radix, inv = read_fatcat_res(i1, i1, fatcat_results)\n",
    "        if afp_1 is None or afp_2 is None:\n",
    "            continue\n",
    "        if len(afp_1) != len(afp_2):\n",
    "            print(i1, i2)\n",
    "        dict_fatcat[radix] = [{r : ind for ind,r in enumerate(afp_1)}, {r : ind for ind, r in enumerate(afp_2)}]\n",
    "    \n",
    "    for i1, i2 in combinations(b+ub, 2):\n",
    "        afp_1, afp_2, radix, inv = read_fatcat_res(i1, i2, fatcat_results)\n",
    "        if afp_1 is None or afp_2 is None:\n",
    "            continue\n",
    "        if len(afp_1) != len(afp_2):\n",
    "            print(i1, i2)\n",
    "        \n",
    "        dict_fatcat[radix] = [{r : ind for ind,r in enumerate(afp_1)}, {r : ind for ind, r in enumerate(afp_2)}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Split according to ssDNA binding interfacenetworkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def get_data(str_x, only_interactions):\n",
    "    data = get_name_data(str_x)\n",
    "    s = only_interactions[(only_interactions[\"structureId\"] == data[0])\n",
    "                        & (only_interactions[\"chainId\"] == data[1])\n",
    "                        & (only_interactions[\"int_ssDNA_chain\"] == data[2])]\n",
    "    \n",
    "    ssDNA_int = flatten(list(map(eval, s.ssDNA_int)))\n",
    "    ssDNA_int = \"' '\".join([f\"{i}\" for i in ssDNA_int])\n",
    "    \n",
    "    return s, ssDNA_int, data[0], data[1], data[2]\n",
    "\n",
    "def flatten(l):\n",
    "    r = [item for sublist in l for ssublist in sublist for item in ssublist]\n",
    "    return r\n",
    "\n",
    "def get_name_data(str_x):\n",
    "    data = str_x.split(\"/\")[-1].split(\"_\")\n",
    "    pdb = data[0].upper()\n",
    "    pc = data[1]\n",
    "    dc = data[2][:-4]\n",
    "    \n",
    "    return pdb, pc, dc\n",
    "\n",
    "def def_contacts(str_1, mol_1, only_interactions, th):\n",
    "    s_1, ssDNA_int_1,pdb_1,pc_1,dc_1 = get_data(str_1, only_interactions)\n",
    "    q = f\"chain {pc_1} and (within {th} of (chain {dc_1} and resid '{ssDNA_int_1}'))\"\n",
    "    try:\n",
    "        sel_1 = atomsel(q, mol_1)\n",
    "#         if \"6pb5_C_2\" in str_1:\n",
    "#             print(sel_1)\n",
    "    except:\n",
    "        print(q, str_1,ssDNA_int_1)\n",
    "        return None, None, None\n",
    "#     if len(sel_1) == 0:\n",
    "#         print(s_1)\n",
    "    return sel_1, dc_1, s_1\n",
    "\n",
    "def get_radix(i1, i2, dict_fatcat):\n",
    "    if f\"{i1[0].lower()}_{i2[0].lower()}\" in dict_fatcat.keys():\n",
    "        return f\"{i1[0].lower()}_{i2[0].lower()}\"\n",
    "    elif f\"{i2[0].lower()}_{i1[0].lower()}\" in dict_fatcat.keys():\n",
    "        return f\"{i2[0].lower()}_{i1[0].lower()}\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def clean_int(str_1, s_1, only_interactions, df_bound_unbound):\n",
    "    data = get_name_data(str_1)\n",
    "    only_interactions.drop(s_1.index[0], inplace = True)\n",
    "    s = only_interactions[(only_interactions[\"structureId\"] == data[0])\n",
    "     & (only_interactions[\"chainId\"] == data[1])]\n",
    "#     print(\"d\", s)\n",
    "    if len(s) == 0:\n",
    "        df_bound_unbound.loc[i,\"boundId\"] = df_bound_unbound.loc[i,\"boundId\"].replace(f\"{data[0]}_{data[1]}\", \"\").strip().replace(\"  \", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def find_proteins_interacting_with_ssDNA(ldict_ssDNA, only_interactions, th):\n",
    "    ldict_contact = {}\n",
    "    for i1 in ldict_ssDNA.items():\n",
    "        for str_1, mol_1 in zip(*i1[1]):\n",
    "            contacts, dc_1, s_1 = def_contacts(str_1, mol_1, only_interactions, th)\n",
    "            if contacts is None:\n",
    "                continue\n",
    "            # If no contact, delete it\n",
    "            if len(contacts) == 0:\n",
    "                clean_int(str_1, s_1, only_interactions, df_bound_unbound)\n",
    "            ldict_contact[i1[0]+\"_\"+dc_1] = set(contacts.resid)\n",
    "    return ldict_contact\n",
    "\n",
    "def get_coms(str_1, str_2, ref_1, ref_2):\n",
    "    pdb_1,pc_1,dc_1 = get_name_data(str_1)\n",
    "    sel_1 = ldict_contact[f\"{pdb_1.lower()}_{pc_1}_{dc_1}\"]\n",
    "    com_1 = set([ref_1[res] for res in set(sel_1) if res in ref_1.keys()])\n",
    "        \n",
    "    pdb_2,pc_2,dc_2 = get_name_data(str_2)\n",
    "    sel_2 = ldict_contact[f\"{pdb_2.lower()}_{pc_2}_{dc_2}\"]\n",
    "    com_2 = set([ref_2[res] for res in set(sel_2) if res in ref_2.keys()])\n",
    "    return com_1, com_2\n",
    "\n",
    "def get_sq_pd(lssDNA, fn):\n",
    "    sq_np = np.ones((len(lssDNA), len(lssDNA)))\n",
    "    np.fill_diagonal(sq_np, 0)\n",
    "    return pd.DataFrame(data=sq_np, index=fn, columns=fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "only_interactions = pd.read_csv(\"csv_tables/ssDNA_interacting.csv\", index_col = 0)\n",
    "df_bound_unbound = pd.read_csv(\"./csv_tables/bound_unbound.preFATCAT.csv\", index_col = 0)\n",
    "split_bound_unbound = pd.DataFrame(columns = df_bound_unbound.columns)\n",
    "new_idx = []\n",
    "\n",
    "for i,(cl, b,_,_,_,_,) in tqdm(df_bound_unbound.iterrows(), total = len(df_bound_unbound)):\n",
    "    b = b.split(\" \")\n",
    "    cb = len(b)\n",
    "#     if i != 2:\n",
    "#         continue\n",
    "    if cb == 1: \n",
    "        print(\"u\", i)\n",
    "        split_bound_unbound = split_bound_unbound.append(df_bound_unbound.loc[i])\n",
    "        new_idx.append(i)\n",
    "        continue\n",
    "        \n",
    "    th = 5.0\n",
    "    ldict_ssDNA = {f\"{j[:4].lower()}_{j[5:].upper()}\" : [glob(f\"./pdb_ssDNAProtChains/{j[:4].lower()}_{j[5:].upper()}*\"), [molecule.load(\"pdb\", k) for k in glob(f\"./pdb_ssDNAProtChains/{j[:4].lower()}_{j[5:].upper()}*\")]] for j in b}\n",
    "\n",
    "    # Find protein residues interacting with ssDNA\n",
    "    ldict_contact = {}\n",
    "    ldict_contact =find_proteins_interacting_with_ssDNA(ldict_ssDNA, only_interactions, th)\n",
    "    \n",
    "    # Second check, after cleaning\n",
    "    b = df_bound_unbound.loc[i, \"boundId\"]\n",
    "    b = b.split(\" \")\n",
    "    cb = len(b)\n",
    "    if cb == 1: \n",
    "        print(\"u\", i)\n",
    "        split_bound_unbound = split_bound_unbound.append(df_bound_unbound.loc[i])\n",
    "        new_idx.append(i)\n",
    "        continue\n",
    "    \n",
    "    ldict_ssDNA = {f\"{j[:4].lower()}_{j[5:].upper()}\" : [glob(f\"./pdb_ssDNAProtChains/{j[:4].lower()}_{j[5:].upper()}*\"), \n",
    "                                                        [molecule.load(\"pdb\", k)\n",
    "                                                        for k in glob(f\"./pdb_ssDNAProtChains/{j[:4].lower()}_{j[5:].upper()}*\")]]\n",
    "                   for j in b}\n",
    "    lssDNA = [[j,[k, molecule.load(\"pdb\", k)]] for j in b for k in glob(f\"./pdb_ssDNAProtChains/{j[:4].lower()}_{j[5:].upper()}*\")]\n",
    "    fn = [k for j in b for k in glob(f\"./pdb_ssDNAProtChains/{j[:4].lower()}_{j[5:].upper()}*\")]\n",
    "    comb = list(combinations(lssDNA, 2))[:]\n",
    "    no_double = True\n",
    "    double_count = 0\n",
    "    \n",
    "    sq_pd = get_sq_pd(lssDNA, fn)\n",
    "    \n",
    "    for i1, i2 in comb:\n",
    "        radix = get_radix(i1, i2, dict_fatcat)\n",
    "#         print(radix)\n",
    "        if radix is None:\n",
    "            continue\n",
    "        ref_1, ref_2 = dict_fatcat[radix]\n",
    "        \n",
    "        # List Bound pairs to compare ssDNA interface\n",
    "        (str_1, mol_1), (str_2, mol_2) = i1[1], i2[1]\n",
    "        com_1, com_2 = get_coms(str_1, str_2, ref_1, ref_2)\n",
    "                \n",
    "        ui = com_1.intersection(com_2)\n",
    "        if len(ui) == 0:\n",
    "            sq_pd.loc[str_1, str_2] = 0\n",
    "            sq_pd.loc[str_2, str_1] = 0\n",
    "            no_double = False\n",
    "            double_count+=1\n",
    "\n",
    "#     print(sq_pd.sum())\n",
    "    if no_double:\n",
    "        print(\"s\", i)\n",
    "        split_bound_unbound = split_bound_unbound.append(df_bound_unbound.loc[i])\n",
    "        new_idx.append(i)\n",
    "        pass\n",
    "    else:\n",
    "        G = nx.from_pandas_adjacency(sq_pd)\n",
    "        lG = [len(c) for c in sorted(nx.connected_components(G), key=len, reverse=True)]\n",
    "        if len(lG) == 1:\n",
    "            split_bound_unbound = split_bound_unbound.append(df_bound_unbound.loc[i])\n",
    "            new_idx.append(i)\n",
    "        else:\n",
    "            for idx, c in enumerate(nx.connected_components(G)):\n",
    "                split_bound_unbound = split_bound_unbound.append(df_bound_unbound.loc[i])\n",
    "                new_bId = map(str.upper, c)\n",
    "                new_bId = [x.split(\"/\")[-1][:-4] for x in new_bId]\n",
    "                new_bId = \" \".join(new_bId)\n",
    "                split_bound_unbound.iloc[-1, split_bound_unbound.columns.get_loc('boundId')] = new_bId\n",
    "                new_idx.append(f\"{i}.{idx+1}\")\n",
    "        print(\"d\", i, double_count, len(comb), lG)\n",
    "    \n",
    "    for mol in molecule.listall():\n",
    "        molecule.delete(mol)\n",
    "split_bound_unbound.index = new_idx\n",
    "for mol in molecule.listall():\n",
    "    molecule.delete(mol)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Remove unbound structure with missing interface residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fatcat_results = set(glob(\"./results_fatcat/*chain*\"))\n",
    "only_interactions = pd.read_csv(\"csv_tables/ssDNA_interacting.csv\", index_col = 0)\n",
    "pdb_chains = set(glob(\"./pdb_chains/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def most_frequent(List):\n",
    "    return max(set(List), key = List.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "nan_value = float(\"NaN\")\n",
    "interface_pd = split_bound_unbound.copy(deep = True)\n",
    "\n",
    "for i,(cl, b,ub, _,_,_,) in tqdm(interface_pd.iterrows(), total = len(interface_pd)):\n",
    "#     if i != 0:\n",
    "#         continue\n",
    "    b = b.split(\" \")\n",
    "    ub = ub.split(\" \")\n",
    "    \n",
    "    th = 5.0\n",
    "    ldict_ssDNA = {f\"{j[:4].lower()}_{j[5:].upper()}\" : [glob(f\"./pdb_ssDNAProtChains/{j[:4].lower()}_{j[5:].upper()}*\"), [molecule.load(\"pdb\", k) for k in glob(f\"./pdb_ssDNAProtChains/{j[:4].lower()}_{j[5:].upper()}*\")]] for j in b}\n",
    "    ldict_chain = {j.lower() : [molecule.load(\"pdb\", f\"./pdb_chains/{j.lower()}.pdb\")] for j in ub if f\"./pdb_chains/{j.lower()}.pdb\" in pdb_chains}\n",
    "    for k, mol in ldict_chain.items():\n",
    "        ldict_chain[k].append(set(atomsel(\"all\", mol[0]).resid))\n",
    "    \n",
    "    lssDNA = [[j,[k, molecule.load(\"pdb\", k)]] for j in b for k in glob(f\"./pdb_ssDNAProtChains/{j[:4].lower()}_{j[5:].upper()}*\")]\n",
    "    ldict_contact =find_proteins_interacting_with_ssDNA(ldict_ssDNA, only_interactions, th)\n",
    "    \n",
    "    ub_ok = []\n",
    "    for bcont, (bf, mol_1) in lssDNA:\n",
    "        bcont = \"_\".join(bcont.split(\"_\")[:2])\n",
    "        ssCont = set([it for k in ldict_contact.items()  for it in k[1] if bcont.upper() == k[0][:len(bcont)].upper()])\n",
    "#         print(ssCont)\n",
    "        partial_ub_ok = []\n",
    "        for ubs in ub:\n",
    "            afp_1, afp_2, radix, inv = read_fatcat_res(bcont, ubs, fatcat_results)\n",
    "            if afp_1 is None or afp_2 is None:\n",
    "                continue\n",
    "            if not inv:\n",
    "                afp_b, afp_ub = afp_1, afp_2\n",
    "            else:\n",
    "                afp_ub, afp_b = afp_1, afp_2\n",
    "            \n",
    "            diff = set([iub - ib for ib, iub in zip(afp_b, afp_ub)])\n",
    "            if len(diff) == 1:\n",
    "                ofset = list(diff)[0]\n",
    "            else:\n",
    "                ofset = most_frequent([iub - ib  for ib, iub in zip(afp_b, afp_ub)])\n",
    "#             print(bcont, ubs, ofset)\n",
    "#             print(afp_1)\n",
    "#             print(afp_2)\n",
    "                \n",
    "            ubCont = set([resid + ofset for resid in ssCont ])\n",
    "            ubRes = ldict_chain[ubs.lower()][1]\n",
    "#             print(ubRes)\n",
    "            diff_bUb = ubCont.difference(ubRes)\n",
    "#             print(diff_bUb)\n",
    "            if len(diff_bUb) != 0 or True:\n",
    "                partial_ub_ok.append(ubs)\n",
    "                continue\n",
    "#             else:\n",
    "#                 print(bcont, ubs, radix, diff)\n",
    "#                 print(ubRes)\n",
    "#                 print(ubCont)\n",
    "        ub_ok.append(set(partial_ub_ok))\n",
    "    interface_pd.loc[i,\"unboundId\"] = \" \".join(set.intersection(*ub_ok))\n",
    "                \n",
    "#             break\n",
    "#         break\n",
    "#     break\n",
    "interface_pd = interface_pd.replace(\"\", nan_value, inplace=False).dropna(subset = [\"unboundId\"], inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "cl = interface_pd[f\"clusterNumber{clusterNumber}\"].to_list()\n",
    "idx = interface_pd.index\n",
    "\n",
    "cur_idx = 0\n",
    "sub_idx = 1\n",
    "new_idx = []\n",
    "for i in range(len(cl)-1):\n",
    "    if cl[i] != cl[i+1] and sub_idx == 1:\n",
    "        new_idx.append(str(cur_idx))\n",
    "        cur_idx += 1\n",
    "    if cl[i] != cl[i+1] and sub_idx != 1:\n",
    "        new_idx.append(f\"{cur_idx}.{sub_idx}\")\n",
    "        sub_idx = 1\n",
    "        cur_idx += 1\n",
    "    if cl[i] == cl[i+1]:\n",
    "        new_idx.append(f\"{cur_idx}.{sub_idx}\")\n",
    "        sub_idx += 1\n",
    "if cl[-1] == cl[-2]:\n",
    "    new_idx.append(f\"{cur_idx}.{sub_idx}\")\n",
    "else:\n",
    "    new_idx.append(str(cur_idx))\n",
    "\n",
    "interface_pd.index = new_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "interface_pd.to_csv(\"./csv_tables/bound_unbound.cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "interface_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# RMSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Convert PDB_id pairs into RMSD matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Read RMSD from fatcat results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fatcat_fileList = glob(\"./results_fatcat/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rmsdList = []\n",
    "for f in tqdm(fatcat_fileList[:]):\n",
    "    s1,c1,s2,c2 = f[17:-10].split(\"_\")\n",
    "    try:\n",
    "        fc = open(f, \"r\").read().split(\"\\n\")\n",
    "        RMSD_line = fc[15]\n",
    "        r = float(RMSD_line.split(\" \")[7][:-1])\n",
    "        rmsdList.append([f\"{s1}_{c1}\", f\"{s2}_{c2}\", r])\n",
    "    except Exception as e:\n",
    "        print(f)\n",
    "        pass\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Convert list of RMSD into dict of dict then into dict of Tables/dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "rmsdDict = {}\n",
    "for l in rmsdList:\n",
    "    ####\n",
    "    if l[0] in rmsdDict.keys():\n",
    "        rmsdDict[l[0]][l[1]] = l[2]\n",
    "    else:\n",
    "        rmsdDict[l[0]] = {l[1]:l[2]}\n",
    "    ####\n",
    "    if l[1] in rmsdDict.keys():\n",
    "        rmsdDict[l[1]][l[0]] = l[2]\n",
    "    else:\n",
    "        rmsdDict[l[1]] = {l[0]:l[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rmsdDict['6gh5_d']['5vsw_d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "failed_rmsd = []\n",
    "rmsd_tables = {}\n",
    "# split_bound_unbound = pd.read_csv(\"csv_tables/bound_unbound.cleaned.csv\", index_col = 0)\n",
    "\n",
    "for i, r in tqdm(interface_pd.iterrows(), total = len(interface_pd)):\n",
    "    bounds = r.boundId.split(\" \")\n",
    "    bounds = [\"_\".join(b.split(\"_\")[:2]) for b in bounds]\n",
    "    unbounds = r.unboundId.split(\" \")\n",
    "    str_names = [\"\"+b.lower()+\".pdb\" for b in bounds] + [\"\"+ b.lower() +\".pdb\" for b in unbounds]\n",
    "    str_names_forMatrix = [\"(b)\"+b.lower() for b in bounds] + [\"(ub)\"+ b.lower() for b in unbounds]\n",
    "    \n",
    "    d = pd.DataFrame(0, index=str_names_forMatrix, columns=str_names_forMatrix)\n",
    "    \n",
    "    for i1, (m1, n1) in enumerate(zip(str_names, str_names_forMatrix)):\n",
    "        tmp_col = []\n",
    "        for i2, (m2, n2) in enumerate(zip(str_names, str_names_forMatrix)):\n",
    "            if i2 == i1 :\n",
    "                tmp_col.append(0)\n",
    "                continue\n",
    "            try:\n",
    "                tmp_col.append(rmsdDict[m1[:-4]][m2[:-4]])\n",
    "            except KeyError:\n",
    "                tmp_col.append(0.0)\n",
    "                if m1 not in rmsdDict.keys():\n",
    "                    failed_rmsd.append(m1)\n",
    "                if m2 not in rmsdDict.keys():\n",
    "                    failed_rmsd.append(m2)\n",
    "        d.loc[n1, :] = tmp_col\n",
    "    \n",
    "    rmsd_tables[i] = d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### TODO : remove failed FATCAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(uniq(failed_rmsd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "# Save all tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## \"Redundant\" table, ie with chains ~~from the same main structures~~ with low RMSD (<0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "interface_pd.to_csv(\"./csv_tables/bound_unbound.redundant.csv\", float_format='%.1f')\n",
    "interface_pd.to_excel(\"./csv_tables/bound_unbound.redundant.xlsx\", float_format='%.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('./csv_tables/final_sup_RMSD.redundant.xlsx')\n",
    "\n",
    "# Write each dataframe to a different worksheet.\n",
    "for i,j in tqdm(zip(rmsd_tables.keys(), rmsd_tables.values()), total=len(rmsd_tables)):\n",
    "    try:\n",
    "#         print(j)\n",
    "        j.to_excel(writer, sheet_name=f'{i}')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## \"NON-Redundant\" table, ie without UNBOUND chains ~~from the same main structures~~ with low RMSD (<0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('./csv_tables/final_sup_RMSD.non_redundant.xlsx')\n",
    "drop_rmsd_tables = rmsd_tables.copy()\n",
    "\n",
    "def keep_index(close_index, index):\n",
    "#     print(\"-\", close_index)\n",
    "#     print(\"-\", index)\n",
    "    index_to_notkeep = []\n",
    "    index_to_keep = []\n",
    "    for i1,i2 in zip(*close_index):\n",
    "        if i1 < i2:\n",
    "            index_to_notkeep.append(i2)\n",
    "        elif i2 not in index_to_notkeep:\n",
    "            index_to_keep.append(i2)\n",
    "            \n",
    "    index_to_keep = uniq(index_to_keep)\n",
    "    index_to_notkeep = uniq(index_to_notkeep)\n",
    "#     index_to_notkeep = sorted(list(set(index_to_notkeep).intersection(set(index_to_keep))))\n",
    "#     name_to_notkeep = [index[tnk] for tnk in index_to_notkeep  if \"(ub)\" in index[tnk]]\n",
    "    name_to_notkeep = [index[tnk] for tnk in index_to_notkeep]\n",
    "    \n",
    "    return name_to_notkeep\n",
    "\n",
    "# Write each dataframe to a different worksheet.\n",
    "# todo = [0, 109]\n",
    "for i,j in tqdm(zip(drop_rmsd_tables.keys(), drop_rmsd_tables.values()), total=len(drop_rmsd_tables)):\n",
    "#     if i not in todo:\n",
    "#         continue\n",
    "    \n",
    "    b_index_to_keep = []\n",
    "    b_index_to_notkeep = []\n",
    "    ub_index_to_keep = []\n",
    "    ub_index_to_notkeep = []\n",
    "    \n",
    "    index = j.index\n",
    "    table = j.to_numpy(dtype = float)\n",
    "    \n",
    "    bound_names = [k for k in index if \"(b)\" in k]\n",
    "    unbound_names = [k for k in index if \"(ub)\" in k]\n",
    "    \n",
    "    bound_table = j.loc[bound_names, bound_names].to_numpy(dtype = float)\n",
    "    unbound_table = j.loc[unbound_names, unbound_names].to_numpy(dtype = float)\n",
    "    bound_index = j.loc[bound_names, bound_names].index\n",
    "    unbound_index = j.loc[unbound_names, unbound_names].index\n",
    "    \n",
    "    # Check values under threshold, and exclude diagonal\n",
    "    close_b = bound_table < 0.2\n",
    "    close_ub = unbound_table < 0.2\n",
    "    np.fill_diagonal(close_b, False)\n",
    "    np.fill_diagonal(close_ub, False)\n",
    "    \n",
    "    close_b_index = np.where(close_b == True)\n",
    "    close_ub_index = np.where(close_ub == True)\n",
    "        \n",
    "    # Get one name to keep, remove the others\n",
    "    b_name_to_notkeep  = keep_index(close_b_index, bound_index)\n",
    "    ub_name_to_notkeep = keep_index(close_ub_index, unbound_index)\n",
    "    \n",
    "#     index_to_keep = uniq(index_to_keep)\n",
    "#     index_to_notkeep = uniq(index_to_notkeep)\n",
    "#     index_to_notkeep = sorted(list(set(index_to_notkeep).intersection(set(index_to_keep))))\n",
    "#     name_to_notkeep = [index[tnk] for tnk in index_to_notkeep  if \"(ub)\" in index[tnk]]\n",
    "        \n",
    "    # Modify table\n",
    "    drop_rmsd_tables[i] = drop_rmsd_tables[i].drop(b_name_to_notkeep)\n",
    "    drop_rmsd_tables[i] = drop_rmsd_tables[i].drop(b_name_to_notkeep, axis = 1)\n",
    "    drop_rmsd_tables[i] = drop_rmsd_tables[i].drop(ub_name_to_notkeep)\n",
    "    drop_rmsd_tables[i] = drop_rmsd_tables[i].drop(ub_name_to_notkeep, axis = 1)\n",
    "    \n",
    "#     if i in todo:\n",
    "#         print(table)\n",
    "#         print(drop_rmsd_tables[i])\n",
    "#         print(b_name_to_notkeep)\n",
    "    \n",
    "    try:\n",
    "        drop_rmsd_tables[i].to_excel(writer, sheet_name=f'{i}')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Update main table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "unboundId = []\n",
    "boundId = []\n",
    "\n",
    "for i,j in tqdm(zip(drop_rmsd_tables.keys(), drop_rmsd_tables.values()), total=len(drop_rmsd_tables)):\n",
    "    # Get unbound names from the modified RMSD table\n",
    "    j_ub = [n for n in j.index if \"(ub)\" in n]\n",
    "    j_ub = [n.replace(\"(ub)\", \"\") for n in j_ub]\n",
    "    j_ub = [n.upper() for n in j_ub]\n",
    "    ub_list = \" \".join(j_ub)\n",
    "    \n",
    "    # Modify the table unbound value\n",
    "    unboundId.append(ub_list)\n",
    "    \n",
    "    ####    ####    ####    ####    ####    ####    ##\n",
    "    # Get unbound names from the modified RMSD table #\n",
    "    ####    ####    ####    ####    ####    ####    ##\n",
    "    j_b = [n for n in j.index if \"(b)\" in n]\n",
    "    j_b = [n.replace(\"(b)\", \"\") for n in j_b]\n",
    "    j_b = [n.upper() for n in j_b]\n",
    "    b_list = \" \".join(j_b)\n",
    "    \n",
    "    # Modify the table unbound value\n",
    "    boundId.append(b_list)\n",
    "    \n",
    "interface_pd.unboundId = unboundId\n",
    "interface_pd.boundId = boundId\n",
    "\n",
    "# df_new_index.replace('', np.nan, inplace=True)\n",
    "# df_new_index.dropna(inplace=True)\n",
    "    \n",
    "interface_pd.to_csv(\"./csv_tables/bound_unbound.non_redundant.csv\", float_format='%.1f')\n",
    "interface_pd.to_excel(\"./csv_tables/bound_unbound.non_redundant.xlsx\", float_format='%.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Sequence homology table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "cluster_src = \"https://cdn.rcsb.org/resources/sequence/clusters/\"\n",
    "#\"bc-30.out\"\n",
    "cluster_pct = [100, 95, 90, 70, 50, 40, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for pct in tqdm(cluster_pct):\n",
    "    download_file(f\"{cluster_src}bc-{pct}.out\", f\"rcsb_clustering/bc-{pct}.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pct_to_member = {}\n",
    "for pct in cluster_pct:\n",
    "    clfile = open(f\"rcsb_clustering/bc-{pct}.out\", \"r\").read().split(\"\\n\")\n",
    "    \n",
    "    pct_to_member[pct] = [content.split(\" \") for content in clfile if content != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pct_to_member_to_cl = {}\n",
    "for pct in tqdm(cluster_pct):\n",
    "    pct_to_member_to_cl[pct] = {}\n",
    "    members_list = pct_to_member[pct]\n",
    "    for i, members in enumerate(members_list):\n",
    "        for member in members:\n",
    "            pct_to_member_to_cl[pct][member] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "first_bound_list = []\n",
    "for i, (cl, b, ub, _, _, _,) in tqdm(interface_pd.iterrows(), total = len(interface_pd)):\n",
    "    b = b.split(\" \")[0]\n",
    "    b = \"_\".join(b.split(\"_\")[:2])\n",
    "    first_bound_list.append((i, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sq_np = np.zeros([len(interface_pd), len(interface_pd)])\n",
    "np.fill_diagonal(sq_np, 100)\n",
    "sq_pd = pd.DataFrame(data=sq_np, index=interface_pd.index, columns=interface_pd.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comb = permutations(first_bound_list, 2)\n",
    "for perm in list(comb):\n",
    "    for pct in cluster_pct:\n",
    "        try:\n",
    "            cl_1 = pct_to_member_to_cl[pct][perm[0][1]]\n",
    "            cl_2 = pct_to_member_to_cl[pct][perm[1][1]]\n",
    "            if cl_1 == cl_2:\n",
    "                sq_pd.loc[perm[0][0], perm[1][0]] = pct\n",
    "                break\n",
    "        except:\n",
    "            sq_pd.loc[perm[0][0], perm[1][0]] = \"e\"\n",
    "            continue\n",
    "sq_pd = sq_pd.applymap(lambda x: int(x) if x != \"e\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sq_pd.to_csv(\"csv_tables/final_sup_clusterHomology.csv\", sep = \"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
